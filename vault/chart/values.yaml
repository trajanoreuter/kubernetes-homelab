vault:
  injector:
    enabled: false

  server:
    enabled: true
    enterpriseLicense:
      # The name of the Kubernetes secret that holds the enterprise license. The
      # secret must be in the same namespace that Vault is installed into.
      secretName: ""
      # The key within the Kubernetes secret that holds the enterprise license.
      secretKey: "license"

    # Resource requests, limits, etc. for the server cluster placement. This
    # should map directly to the value of the resources field for a PodSpec.
    # By default no direct resource request is made.

    image:
      repository: "hashicorp/vault"
      tag: "1.16.1"
      # Overrides the default Image Pull Policy
      pullPolicy: IfNotPresent

    # Configure the Update Strategy Type for the StatefulSet
    # See https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
    updateStrategyType: "OnDelete"

    # Configure the logging verbosity for the Vault server.
    # Supported log levels include: trace, debug, info, warn, error
    logLevel: ""

    # Configure the logging format for the Vault server.
    # Supported log formats include: standard, json
    logFormat: "json"

    resources: 
      requests:
        memory: 256Mi
        cpu: 250m
      limits:
        memory: 256Mi

    ingress:
      enabled: false

    readinessProbe:
      enabled: true
      # If you need to use a http path instead of the default exec
      # path: /v1/sys/health?standbyok=true

      # Port number on which readinessProbe will be checked.
      port: 8200
      # When a probe fails, Kubernetes will try failureThreshold times before giving up
      failureThreshold: 2
      # Number of seconds after the container has started before probe initiates
      initialDelaySeconds: 5
      # How often (in seconds) to perform the probe
      periodSeconds: 5
      # Minimum consecutive successes for the probe to be considered successful after having failed
      successThreshold: 1
      # Number of seconds after which the probe times out.
      timeoutSeconds: 3
    # Used to enable a livenessProbe for the pods
    livenessProbe:
      enabled: false
      # Used to define a liveness exec command. If provided, exec is preferred to httpGet (path) as the livenessProbe handler.
      execCommand: []
      # - /bin/sh
      # - -c
      # - /vault/userconfig/mylivenessscript/run.sh
      # Path for the livenessProbe to use httpGet as the livenessProbe handler
      path: "/v1/sys/health?standbyok=true"
      # Port number on which livenessProbe will be checked if httpGet is used as the livenessProbe handler
      port: 8200
      # When a probe fails, Kubernetes will try failureThreshold times before giving up
      failureThreshold: 2
      # Number of seconds after the container has started before probe initiates
      initialDelaySeconds: 60
      # How often (in seconds) to perform the probe
      periodSeconds: 5
      # Minimum consecutive successes for the probe to be considered successful after having failed
      successThreshold: 1
      # Number of seconds after which the probe times out.
      timeoutSeconds: 3

    affinity: |
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: {{ template "vault.name" . }}
                app.kubernetes.io/instance: "{{ .Release.Name }}"
                component: server
            topologyKey: kubernetes.io/hostname

    extraLabels: {}

    # Extra annotations to attach to the server pods
    # This can either be YAML or a YAML-formatted multi-line templated string map
    # of the annotations to apply to the server pods
    annotations: {}

    # Add an annotation to the server configmap and the statefulset pods,
    # vaultproject.io/config-checksum, that is a hash of the Vault configuration.
    # This can be used together with an OnDelete deployment strategy to help
    # identify which pods still need to be deleted during a deployment to pick up
    # any configuration changes.
    configAnnotation: false

    # Enables a headless service to be used by the Vault Statefulset
    service:
      enabled: true
      # Enable or disable the vault-active service, which selects Vault pods that
      # have labeled themselves as the cluster leader with `vault-active: "true"`.
      active:
        enabled: true
        # Extra annotations for the service definition. This can either be YAML or a
        # YAML-formatted multi-line templated string map of the annotations to apply
        # to the active service.
        annotations: {}
      # Enable or disable the vault-standby service, which selects Vault pods that
      # have labeled themselves as a cluster follower with `vault-active: "false"`.
      standby:
        enabled: true
        # Extra annotations for the service definition. This can either be YAML or a
        # YAML-formatted multi-line templated string map of the annotations to apply
        # to the standby service.
        annotations: {}
      # If enabled, the service selectors will include `app.kubernetes.io/instance: {{ .Release.Name }}`
      # When disabled, services may select Vault pods not deployed from the chart.
      # Does not affect the headless vault-internal service with `ClusterIP: None`
      instanceSelector:
        enabled: true
      # clusterIP controls whether a Cluster IP address is attached to the
      # Vault service within Kubernetes.  By default, the Vault service will
      # be given a Cluster IP address, set to None to disable.  When disabled
      # Kubernetes will create a "headless" service.  Headless services can be
      # used to communicate with pods directly through DNS instead of a round-robin
      # load balancer.
      # clusterIP: None

      # Configures the service type for the main Vault service.  Can be ClusterIP
      # or NodePort.
      #type: ClusterIP

      # The IP family and IP families options are to set the behaviour in a dual-stack environment.
      # Omitting these values will let the service fall back to whatever the CNI dictates the defaults
      # should be.
      # These are only supported for kubernetes versions >=1.23.0
      #
      # Configures the service's supported IP family policy, can be either:
      #     SingleStack: Single-stack service. The control plane allocates a cluster IP for the Service, using the first configured service cluster IP range.
      #     PreferDualStack: Allocates IPv4 and IPv6 cluster IPs for the Service.
      #     RequireDualStack: Allocates Service .spec.ClusterIPs from both IPv4 and IPv6 address ranges.
      ipFamilyPolicy: ""

      # Sets the families that should be supported and the order in which they should be applied to ClusterIP as well.
      # Can be IPv4 and/or IPv6.
      ipFamilies: []

      # Do not wait for pods to be ready before including them in the services'
      # targets. Does not apply to the headless service, which is used for
      # cluster-internal communication.
      publishNotReadyAddresses: true

      # The externalTrafficPolicy can be set to either Cluster or Local
      # and is only valid for LoadBalancer and NodePort service types.
      # The default value is Cluster.
      # ref: https://kubernetes.io/docs/concepts/services-networking/service/#external-traffic-policy
      externalTrafficPolicy: Cluster

      # If type is set to "NodePort", a specific nodePort value can be configured,
      # will be random if left blank.
      #nodePort: 30000

      # When HA mode is enabled
      # If type is set to "NodePort", a specific nodePort value can be configured,
      # will be random if left blank.
      #activeNodePort: 30001

      # When HA mode is enabled
      # If type is set to "NodePort", a specific nodePort value can be configured,
      # will be random if left blank.
      #standbyNodePort: 30002

      # Port on which Vault server is listening
      port: 8200
      # Target port to which the service should be mapped to
      targetPort: 8200
      # Extra annotations for the service definition. This can either be YAML or a
      # YAML-formatted multi-line templated string map of the annotations to apply
      # to the service.
      annotations: {}

    # This configures the Vault Statefulset to create a PVC for data
    # storage when using the file or raft backend storage engines.
    # See https://developer.hashicorp.com/vault/docs/configuration/storage to know more
    dataStorage:
      enabled: true
      # Size of the PVC created
      size: 10Gi
      # Location where the PVC will be mounted.
      mountPath: "/vault/data"
      # Name of the storage class to use.  If null it will use the
      # configured default Storage Class.
      storageClass: null
      # Access Mode of the storage device being used for the PVC
      accessMode: ReadWriteOnce
      # Annotations to apply to the PVC
      annotations: {}
      # Labels to apply to the PVC
      labels: {}

    # Persistent Volume Claim (PVC) retention policy
    # ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention
    # Example:
    # persistentVolumeClaimRetentionPolicy:
    #   whenDeleted: Retain
    #   whenScaled: Retain
    persistentVolumeClaimRetentionPolicy: {}

    # This configures the Vault Statefulset to create a PVC for audit
    # logs.  Once Vault is deployed, initialized, and unsealed, Vault must
    # be configured to use this for audit logs.  This will be mounted to
    # /vault/audit
    # See https://developer.hashicorp.com/vault/docs/audit to know more
    auditStorage:
      enabled: false
      # Size of the PVC created
      size: 10Gi
      # Location where the PVC will be mounted.
      mountPath: "/vault/audit"
      # Name of the storage class to use.  If null it will use the
      # configured default Storage Class.
      storageClass: null
      # Access Mode of the storage device being used for the PVC
      accessMode: ReadWriteOnce
      # Annotations to apply to the PVC
      annotations: {}
      # Labels to apply to the PVC
      labels: {}

    # Run Vault in "dev" mode. This requires no further setup, no state management,
    # and no initialization. This is useful for experimenting with Vault without
    # needing to unseal, store keys, et. al. All data is lost on restart - do not
    # use dev mode for anything other than experimenting.
    # See https://developer.hashicorp.com/vault/docs/concepts/dev-server to know more
    dev:
      enabled: false

      # Set VAULT_DEV_ROOT_TOKEN_ID value
      devRootToken: "root"

    # Run Vault in "standalone" mode. This is the default mode that will deploy if
    # no arguments are given to helm. This requires a PVC for data storage to use
    # the "file" backend.  This mode is not highly available and should not be scaled
    # past a single replica.
    standalone:
      enabled: true

      # config is a raw string of default configuration when using a Stateful
      # deployment. Default is to use a PersistentVolumeClaim mounted at /vault/data
      # and store data there. This is only used when using a Replica count of 1, and
      # using a stateful set. This should be HCL.

      # Note: Configuration files are stored in ConfigMaps so sensitive data
      # such as passwords should be either mounted through extraSecretEnvironmentVars
      # or through a Kube secret.  For more information see:
      # https://developer.hashicorp.com/vault/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations
      config: |
        ui = true

        listener "tcp" {
          tls_disable = 1
          address = "[::]:8200"
          cluster_address = "[::]:8201"
          # Enable unauthenticated metrics access (necessary for Prometheus Operator)
          #telemetry {
          #  unauthenticated_metrics_access = "true"
          #}
        }
        storage "file" {
          path = "/vault/data"
        }

        # Example configuration for using auto-unseal, using Google Cloud KMS. The
        # GKMS keys must already exist, and the cluster must have a service account
        # that is authorized to access GCP KMS.
        #seal "gcpckms" {
        #   project     = "vault-helm-dev"
        #   region      = "global"
        #   key_ring    = "vault-helm-unseal-kr"
        #   crypto_key  = "vault-helm-unseal-key"
        #}

        # Example configuration for enabling Prometheus metrics in your config.
        #telemetry {
        #  prometheus_retention_time = "30s"
        #  disable_hostname = true
        #}

    # Run Vault in "HA" mode. There are no storage requirements unless the audit log
    # persistence is required.  In HA mode Vault will configure itself to use Consul
    # for its storage backend.  The default configuration provided will work the Consul
    # Helm project by default.  It is possible to manually configure Vault to use a
    # different HA backend.
    ha:
      enabled: false
      replicas: 3

      # Set the api_addr configuration for Vault HA
      # See https://developer.hashicorp.com/vault/docs/configuration#api_addr
      # If set to null, this will be set to the Pod IP Address
      apiAddr: null

      # Set the cluster_addr confuguration for Vault HA
      # See https://developer.hashicorp.com/vault/docs/configuration#cluster_addr
      # If set to null, this will be set to https://$(HOSTNAME).{{ template "vault.fullname" . }}-internal:8201
      clusterAddr: null

      # Enables Vault's integrated Raft storage.  Unlike the typical HA modes where
      # Vault's persistence is external (such as Consul), enabling Raft mode will create
      # persistent volumes for Vault to store data according to the configuration under server.dataStorage.
      # The Vault cluster will coordinate leader elections and failovers internally.
      raft:

        # Enables Raft integrated storage
        enabled: false
        # Set the Node Raft ID to the name of the pod
        setNodeId: false

        # Note: Configuration files are stored in ConfigMaps so sensitive data
        # such as passwords should be either mounted through extraSecretEnvironmentVars
        # or through a Kube secret.  For more information see:
        # https://developer.hashicorp.com/vault/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations
        config: |
          ui = true

          listener "tcp" {
            tls_disable = 1
            address = "[::]:8200"
            cluster_address = "[::]:8201"
            # Enable unauthenticated metrics access (necessary for Prometheus Operator)
            #telemetry {
            #  unauthenticated_metrics_access = "true"
            #}
          }

          storage "raft" {
            path = "/vault/data"
          }

          service_registration "kubernetes" {}

      # config is a raw string of default configuration when using a Stateful
      # deployment. Default is to use a Consul for its HA storage backend.
      # This should be HCL.

      # Note: Configuration files are stored in ConfigMaps so sensitive data
      # such as passwords should be either mounted through extraSecretEnvironmentVars
      # or through a Kube secret.  For more information see:
      # https://developer.hashicorp.com/vault/docs/platform/k8s/helm/run#protecting-sensitive-vault-configurations
      config: |
        ui = true

        listener "tcp" {
          tls_disable = 1
          address = "[::]:8200"
          cluster_address = "[::]:8201"
        }
        storage "consul" {
          path = "vault"
          address = "HOST_IP:8500"
        }

        service_registration "kubernetes" {}

        # Example configuration for using auto-unseal, using Google Cloud KMS. The
        # GKMS keys must already exist, and the cluster must have a service account
        # that is authorized to access GCP KMS.
        #seal "gcpckms" {
        #   project     = "vault-helm-dev-246514"
        #   region      = "global"
        #   key_ring    = "vault-helm-unseal-kr"
        #   crypto_key  = "vault-helm-unseal-key"
        #}

        # Example configuration for enabling Prometheus metrics.
        # If you are using Prometheus Operator you can enable a ServiceMonitor resource below.
        # You may wish to enable unauthenticated metrics in the listener block above.
        #telemetry {
        #  prometheus_retention_time = "30s"
        #  disable_hostname = true
        #}

      # A disruption budget limits the number of pods of a replicated application
      # that are down simultaneously from voluntary disruptions
      disruptionBudget:
        enabled: true

      # maxUnavailable will default to (n/2)-1 where n is the number of
      # replicas. If you'd like a custom value, you can specify an override here.
        maxUnavailable: null

    # Definition of the serviceAccount used to run Vault.
    # These options are also used when using an external Vault server to validate
    # Kubernetes tokens.
    serviceAccount:
      # Specifies whether a service account should be created
      create: true
      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      name: ""
      # Create a Secret API object to store a non-expiring token for the service account.
      # Prior to v1.24.0, Kubernetes used to generate this secret for each service account by default.
      # Kubernetes now recommends using short-lived tokens from the TokenRequest API or projected volumes instead if possible.
      # For more details, see https://kubernetes.io/docs/concepts/configuration/secret/#service-account-token-secrets
      # serviceAccount.create must be equal to 'true' in order to use this feature.
      createSecret: false
      # Extra annotations for the serviceAccount definition. This can either be
      # YAML or a YAML-formatted multi-line templated string map of the
      # annotations to apply to the serviceAccount.
      annotations: {}
      # Extra labels to attach to the serviceAccount
      # This should be a YAML map of the labels to apply to the serviceAccount
      extraLabels: {}
      # Enable or disable a service account role binding with the permissions required for
      # Vault's Kubernetes service_registration config option.
      # See https://developer.hashicorp.com/vault/docs/configuration/service-registration/kubernetes
      serviceDiscovery:
        enabled: true

    # Settings for the statefulSet used to run Vault.
    statefulSet:
      # Extra annotations for the statefulSet. This can either be YAML or a
      # YAML-formatted multi-line templated string map of the annotations to apply
      # to the statefulSet.
      annotations: {}

      # Set the pod and container security contexts.
      # If not set, these will default to, and for *not* OpenShift:
      # pod:
      #   runAsNonRoot: true
      #   runAsGroup: {{ .Values.server.gid | default 1000 }}
      #   runAsUser: {{ .Values.server.uid | default 100 }}
      #   fsGroup: {{ .Values.server.gid | default 1000 }}
      # container:
      #   allowPrivilegeEscalation: false
      #
      # If not set, these will default to, and for OpenShift:
      # pod: {}
      # container: {}
      securityContext:
        pod: {}
        container: {}

    # Should the server pods run on the host network
    hostNetwork: false

  # Vault UI
  ui:
    # True if you want to create a Service entry for the Vault UI.
    #
    # serviceType can be used to control the type of service created. For
    # example, setting this to "LoadBalancer" will create an external load
    # balancer (for supported K8S installations) to access the UI.
    enabled: true
    publishNotReadyAddresses: true
    # The service should only contain selectors for active Vault pod
    activeVaultPodOnly: false
    serviceType: "ClusterIP"
    serviceNodePort: null
    externalPort: 8200
    targetPort: 8200

    # The IP family and IP families options are to set the behaviour in a dual-stack environment.
    # Omitting these values will let the service fall back to whatever the CNI dictates the defaults
    # should be.
    # These are only supported for kubernetes versions >=1.23.0
    #
    # Configures the service's supported IP family, can be either:
    #     SingleStack: Single-stack service. The control plane allocates a cluster IP for the Service, using the first configured service cluster IP range.
    #     PreferDualStack: Allocates IPv4 and IPv6 cluster IPs for the Service.
    #     RequireDualStack: Allocates Service .spec.ClusterIPs from both IPv4 and IPv6 address ranges.
    serviceIPFamilyPolicy: ""

    # Sets the families that should be supported and the order in which they should be applied to ClusterIP as well
    # Can be IPv4 and/or IPv6.
    serviceIPFamilies: []

    # The externalTrafficPolicy can be set to either Cluster or Local
    # and is only valid for LoadBalancer and NodePort service types.
    # The default value is Cluster.
    # ref: https://kubernetes.io/docs/concepts/services-networking/service/#external-traffic-policy
    externalTrafficPolicy: Cluster

    #loadBalancerSourceRanges:
    #   - 10.0.0.0/16
    #   - 1.78.23.3/32

    # loadBalancerIP:

    # Extra annotations to attach to the ui service
    # This can either be YAML or a YAML-formatted multi-line templated string map
    # of the annotations to apply to the ui service
    annotations: {}

  # Vault is able to collect and publish various runtime metrics.
  # Enabling this feature requires setting adding `telemetry{}` stanza to
  # the Vault configuration. There are a few examples included in the `config` sections above.
  #
  # For more information see:
  # https://developer.hashicorp.com/vault/docs/configuration/telemetry
  # https://developer.hashicorp.com/vault/docs/internals/telemetry
  serverTelemetry:
    # Enable support for the Prometheus Operator. Currently, this chart does not support
    # authenticating to Vault's metrics endpoint, so the following `telemetry{}` must be included
    # in the `listener "tcp"{}` stanza
    #  telemetry {
    #    unauthenticated_metrics_access = "true"
    #  }
    #
    # See the `standalone.config` for a more complete example of this.
    #
    # In addition, a top level `telemetry{}` stanza must also be included in the Vault configuration:
    #
    # example:
    #  telemetry {
    #    prometheus_retention_time = "30s"
    #    disable_hostname = true
    #  }
    #
    # Configuration for monitoring the Vault server.
    serviceMonitor:
      # The Prometheus operator *must* be installed before enabling this feature,
      # if not the chart will fail to install due to missing CustomResourceDefinitions
      # provided by the operator.
      #
      # Instructions on how to install the Helm chart can be found here:
      #  https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
      # More information can be found here:
      #  https://github.com/prometheus-operator/prometheus-operator
      #  https://github.com/prometheus-operator/kube-prometheus

      # Enable deployment of the Vault Server ServiceMonitor CustomResource.
      enabled: false

      # Selector labels to add to the ServiceMonitor.
      # When empty, defaults to:
      #  release: prometheus
      selectors: {}

      # Interval at which Prometheus scrapes metrics
      interval: 30s

      # Timeout for Prometheus scrapes
      scrapeTimeout: 10s

    prometheusRules:
        # The Prometheus operator *must* be installed before enabling this feature,
        # if not the chart will fail to install due to missing CustomResourceDefinitions
        # provided by the operator.

        # Deploy the PrometheusRule custom resource for AlertManager based alerts.
        # Requires that AlertManager is properly deployed.
        enabled: false

        # Selector labels to add to the PrometheusRules.
        # When empty, defaults to:
        #  release: prometheus
        selectors: {}

        # Some example rules.
        rules: []
        #  - alert: vault-HighResponseTime
        #    annotations:
        #      message: The response time of Vault is over 500ms on average over the last 5 minutes.
        #    expr: vault_core_handle_request{quantile="0.5", namespace="mynamespace"} > 500
        #    for: 5m
        #    labels:
        #      severity: warning
        #  - alert: vault-HighResponseTime
        #    annotations:
        #      message: The response time of Vault is over 1s on average over the last 5 minutes.
        #    expr: vault_core_handle_request{quantile="0.5", namespace="mynamespace"} > 1000
        #    for: 5m
        #    labels:
        #      severity: critical
